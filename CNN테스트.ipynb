{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcKkqG1jvlE3",
        "outputId": "0411a34d-6d54-4bc3-a4b4-ba69141301a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.3485, Train Acc: 0.9602, Test Acc: 0.9615\n",
            "Epoch 2, Loss: 0.1114, Train Acc: 0.9721, Test Acc: 0.9711\n",
            "Epoch 3, Loss: 0.0707, Train Acc: 0.9831, Test Acc: 0.9808\n",
            "Epoch 4, Loss: 0.0537, Train Acc: 0.9877, Test Acc: 0.9850\n",
            "Epoch 5, Loss: 0.0436, Train Acc: 0.9909, Test Acc: 0.9871\n",
            "Epoch 6, Loss: 0.0366, Train Acc: 0.9898, Test Acc: 0.9860\n",
            "Epoch 7, Loss: 0.0302, Train Acc: 0.9918, Test Acc: 0.9870\n",
            "Epoch 8, Loss: 0.0263, Train Acc: 0.9942, Test Acc: 0.9878\n",
            "Epoch 9, Loss: 0.0233, Train Acc: 0.9929, Test Acc: 0.9861\n",
            "Epoch 10, Loss: 0.0203, Train Acc: 0.9962, Test Acc: 0.9889\n",
            "Epoch 11, Loss: 0.0180, Train Acc: 0.9966, Test Acc: 0.9890\n",
            "Epoch 12, Loss: 0.0148, Train Acc: 0.9974, Test Acc: 0.9882\n",
            "Epoch 13, Loss: 0.0135, Train Acc: 0.9977, Test Acc: 0.9881\n",
            "Epoch 14, Loss: 0.0119, Train Acc: 0.9985, Test Acc: 0.9899\n",
            "Epoch 15, Loss: 0.0103, Train Acc: 0.9982, Test Acc: 0.9896\n",
            "Epoch 16, Loss: 0.0089, Train Acc: 0.9980, Test Acc: 0.9887\n",
            "Epoch 17, Loss: 0.0075, Train Acc: 0.9988, Test Acc: 0.9894\n",
            "Epoch 18, Loss: 0.0067, Train Acc: 0.9993, Test Acc: 0.9890\n",
            "Epoch 19, Loss: 0.0055, Train Acc: 0.9992, Test Acc: 0.9898\n",
            "Epoch 20, Loss: 0.0050, Train Acc: 0.9994, Test Acc: 0.9888\n",
            "Epoch 21, Loss: 0.0045, Train Acc: 0.9997, Test Acc: 0.9886\n",
            "Epoch 22, Loss: 0.0040, Train Acc: 0.9998, Test Acc: 0.9895\n",
            "Epoch 23, Loss: 0.0034, Train Acc: 0.9998, Test Acc: 0.9900\n",
            "Epoch 24, Loss: 0.0030, Train Acc: 0.9998, Test Acc: 0.9887\n",
            "Epoch 25, Loss: 0.0025, Train Acc: 0.9998, Test Acc: 0.9895\n",
            "Epoch 26, Loss: 0.0024, Train Acc: 0.9998, Test Acc: 0.9892\n",
            "Epoch 27, Loss: 0.0022, Train Acc: 0.9999, Test Acc: 0.9896\n",
            "Epoch 28, Loss: 0.0018, Train Acc: 0.9998, Test Acc: 0.9893\n",
            "Epoch 29, Loss: 0.0016, Train Acc: 0.9998, Test Acc: 0.9895\n",
            "Epoch 30, Loss: 0.0014, Train Acc: 0.9999, Test Acc: 0.9886\n",
            "Epoch 31, Loss: 0.0014, Train Acc: 0.9999, Test Acc: 0.9891\n",
            "Epoch 32, Loss: 0.0012, Train Acc: 1.0000, Test Acc: 0.9891\n",
            "Epoch 33, Loss: 0.0010, Train Acc: 0.9999, Test Acc: 0.9890\n",
            "Epoch 34, Loss: 0.0010, Train Acc: 1.0000, Test Acc: 0.9893\n",
            "Epoch 35, Loss: 0.0009, Train Acc: 1.0000, Test Acc: 0.9890\n",
            "Epoch 36, Loss: 0.0008, Train Acc: 1.0000, Test Acc: 0.9893\n",
            "Epoch 37, Loss: 0.0008, Train Acc: 1.0000, Test Acc: 0.9896\n",
            "Epoch 38, Loss: 0.0007, Train Acc: 1.0000, Test Acc: 0.9891\n",
            "Epoch 39, Loss: 0.0006, Train Acc: 1.0000, Test Acc: 0.9892\n",
            "Epoch 40, Loss: 0.0006, Train Acc: 1.0000, Test Acc: 0.9891\n",
            "Epoch 41, Loss: 0.0006, Train Acc: 1.0000, Test Acc: 0.9890\n",
            "Epoch 42, Loss: 0.0006, Train Acc: 1.0000, Test Acc: 0.9895\n",
            "Epoch 43, Loss: 0.0005, Train Acc: 1.0000, Test Acc: 0.9887\n",
            "Epoch 44, Loss: 0.0005, Train Acc: 1.0000, Test Acc: 0.9890\n",
            "Epoch 45, Loss: 0.0005, Train Acc: 1.0000, Test Acc: 0.9891\n",
            "Epoch 46, Loss: 0.0005, Train Acc: 1.0000, Test Acc: 0.9888\n",
            "Epoch 47, Loss: 0.0004, Train Acc: 1.0000, Test Acc: 0.9891\n",
            "Epoch 48, Loss: 0.0004, Train Acc: 1.0000, Test Acc: 0.9888\n",
            "Epoch 49, Loss: 0.0004, Train Acc: 1.0000, Test Acc: 0.9890\n",
            "Epoch 50, Loss: 0.0004, Train Acc: 1.0000, Test Acc: 0.9889\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
        "        # 12x12 크기로 줄어듦\n",
        "        # OH = ( ( H - FH + ( 2 * P )  ) // S ) + 1\n",
        "        # OW 동일\n",
        "        # ( 28 - 5 + 0 / 1) + 1 = 24\n",
        "        # 28 x 28이미지가 24 x 24 행렬로 전환됨.\n",
        "        # 이후 2x2 maxPool계층을 통과하면\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # 12 x 12 행렬이 됨.\n",
        "        self.fc1 = nn.Linear(30 * 12 * 12, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 30 * 12 * 12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\"./data\", train=True, download=True,\n",
        "                   transform=transforms.ToTensor()), batch_size=100, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(30 * 12 * 12, 100)  # 12x12 크기로 줄어듦\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 30 * 12 * 12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(20),  # 20도 회전\n",
        "    #transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCI-uS8T5nvB",
        "outputId": "ebf08632-0e1a-465e-bb2f-6db1c24c3255"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.2793, Train Acc: 0.9670, Test Acc: 0.8947\n",
            "Epoch 2, Loss: 0.1031, Train Acc: 0.9747, Test Acc: 0.8223\n",
            "Epoch 3, Loss: 0.0804, Train Acc: 0.9772, Test Acc: 0.8970\n",
            "Epoch 4, Loss: 0.0684, Train Acc: 0.9835, Test Acc: 0.8485\n",
            "Epoch 5, Loss: 0.0599, Train Acc: 0.9836, Test Acc: 0.8437\n",
            "Epoch 6, Loss: 0.0563, Train Acc: 0.9856, Test Acc: 0.9188\n",
            "Epoch 7, Loss: 0.0511, Train Acc: 0.9853, Test Acc: 0.8829\n",
            "Epoch 8, Loss: 0.0462, Train Acc: 0.9855, Test Acc: 0.9443\n",
            "Epoch 9, Loss: 0.0438, Train Acc: 0.9870, Test Acc: 0.9021\n",
            "Epoch 10, Loss: 0.0401, Train Acc: 0.9876, Test Acc: 0.9415\n",
            "Epoch 11, Loss: 0.0384, Train Acc: 0.9899, Test Acc: 0.9530\n",
            "Epoch 12, Loss: 0.0366, Train Acc: 0.9903, Test Acc: 0.9445\n",
            "Epoch 13, Loss: 0.0350, Train Acc: 0.9888, Test Acc: 0.9211\n",
            "Epoch 14, Loss: 0.0321, Train Acc: 0.9887, Test Acc: 0.9226\n",
            "Epoch 15, Loss: 0.0292, Train Acc: 0.9921, Test Acc: 0.9551\n",
            "Epoch 16, Loss: 0.0302, Train Acc: 0.9926, Test Acc: 0.9572\n",
            "Epoch 17, Loss: 0.0279, Train Acc: 0.9933, Test Acc: 0.9629\n",
            "Epoch 18, Loss: 0.0278, Train Acc: 0.9919, Test Acc: 0.9401\n",
            "Epoch 19, Loss: 0.0250, Train Acc: 0.9930, Test Acc: 0.9537\n",
            "Epoch 20, Loss: 0.0239, Train Acc: 0.9941, Test Acc: 0.9671\n",
            "Epoch 21, Loss: 0.0224, Train Acc: 0.9910, Test Acc: 0.9403\n",
            "Epoch 22, Loss: 0.0244, Train Acc: 0.9939, Test Acc: 0.9731\n",
            "Epoch 23, Loss: 0.0217, Train Acc: 0.9938, Test Acc: 0.9488\n",
            "Epoch 24, Loss: 0.0208, Train Acc: 0.9917, Test Acc: 0.9556\n",
            "Epoch 25, Loss: 0.0204, Train Acc: 0.9948, Test Acc: 0.9513\n",
            "Epoch 26, Loss: 0.0192, Train Acc: 0.9948, Test Acc: 0.9597\n",
            "Epoch 27, Loss: 0.0173, Train Acc: 0.9943, Test Acc: 0.9534\n",
            "Epoch 28, Loss: 0.0172, Train Acc: 0.9944, Test Acc: 0.9455\n",
            "Epoch 29, Loss: 0.0175, Train Acc: 0.9943, Test Acc: 0.9597\n",
            "Epoch 30, Loss: 0.0162, Train Acc: 0.9947, Test Acc: 0.9264\n",
            "Epoch 31, Loss: 0.0164, Train Acc: 0.9953, Test Acc: 0.9609\n",
            "Epoch 32, Loss: 0.0155, Train Acc: 0.9948, Test Acc: 0.9628\n",
            "Epoch 33, Loss: 0.0138, Train Acc: 0.9950, Test Acc: 0.9522\n",
            "Epoch 34, Loss: 0.0145, Train Acc: 0.9942, Test Acc: 0.9671\n",
            "Epoch 35, Loss: 0.0136, Train Acc: 0.9966, Test Acc: 0.9553\n",
            "Epoch 36, Loss: 0.0128, Train Acc: 0.9952, Test Acc: 0.9598\n",
            "Epoch 37, Loss: 0.0141, Train Acc: 0.9958, Test Acc: 0.9576\n",
            "Epoch 38, Loss: 0.0135, Train Acc: 0.9956, Test Acc: 0.9451\n",
            "Epoch 39, Loss: 0.0112, Train Acc: 0.9961, Test Acc: 0.9527\n",
            "Epoch 40, Loss: 0.0114, Train Acc: 0.9958, Test Acc: 0.9569\n",
            "Epoch 41, Loss: 0.0114, Train Acc: 0.9964, Test Acc: 0.9629\n",
            "Epoch 42, Loss: 0.0116, Train Acc: 0.9968, Test Acc: 0.9565\n",
            "Epoch 43, Loss: 0.0122, Train Acc: 0.9965, Test Acc: 0.9575\n",
            "Epoch 44, Loss: 0.0102, Train Acc: 0.9965, Test Acc: 0.9698\n",
            "Epoch 45, Loss: 0.0111, Train Acc: 0.9961, Test Acc: 0.9441\n",
            "Epoch 46, Loss: 0.0117, Train Acc: 0.9952, Test Acc: 0.9651\n",
            "Epoch 47, Loss: 0.0094, Train Acc: 0.9961, Test Acc: 0.9538\n",
            "Epoch 48, Loss: 0.0104, Train Acc: 0.9967, Test Acc: 0.9693\n",
            "Epoch 49, Loss: 0.0106, Train Acc: 0.9974, Test Acc: 0.9725\n",
            "Epoch 50, Loss: 0.0091, Train Acc: 0.9970, Test Acc: 0.9620\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(30 * 12 * 12, 100)  # 12x12 크기로 줄어듦\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 30 * 12 * 12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    #transforms.RandomRotation(20),  # 20도 회전\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6zEWYgvHrwF",
        "outputId": "af7f4fa9-1240-4aae-bc58-5cce016268e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.2413, Train Acc: 0.9654, Test Acc: 0.7923\n",
            "Epoch 2, Loss: 0.0897, Train Acc: 0.9750, Test Acc: 0.9047\n",
            "Epoch 3, Loss: 0.0684, Train Acc: 0.9837, Test Acc: 0.9284\n",
            "Epoch 4, Loss: 0.0564, Train Acc: 0.9845, Test Acc: 0.9338\n",
            "Epoch 5, Loss: 0.0525, Train Acc: 0.9850, Test Acc: 0.9525\n",
            "Epoch 6, Loss: 0.0460, Train Acc: 0.9886, Test Acc: 0.9615\n",
            "Epoch 7, Loss: 0.0409, Train Acc: 0.9877, Test Acc: 0.9478\n",
            "Epoch 8, Loss: 0.0375, Train Acc: 0.9891, Test Acc: 0.9426\n",
            "Epoch 9, Loss: 0.0354, Train Acc: 0.9905, Test Acc: 0.9743\n",
            "Epoch 10, Loss: 0.0327, Train Acc: 0.9904, Test Acc: 0.9562\n",
            "Epoch 11, Loss: 0.0314, Train Acc: 0.9916, Test Acc: 0.9661\n",
            "Epoch 12, Loss: 0.0280, Train Acc: 0.9908, Test Acc: 0.9336\n",
            "Epoch 13, Loss: 0.0258, Train Acc: 0.9937, Test Acc: 0.9568\n",
            "Epoch 14, Loss: 0.0255, Train Acc: 0.9930, Test Acc: 0.9542\n",
            "Epoch 15, Loss: 0.0235, Train Acc: 0.9927, Test Acc: 0.9544\n",
            "Epoch 16, Loss: 0.0235, Train Acc: 0.9942, Test Acc: 0.9562\n",
            "Epoch 17, Loss: 0.0221, Train Acc: 0.9929, Test Acc: 0.9485\n",
            "Epoch 18, Loss: 0.0200, Train Acc: 0.9947, Test Acc: 0.9437\n",
            "Epoch 19, Loss: 0.0201, Train Acc: 0.9952, Test Acc: 0.9615\n",
            "Epoch 20, Loss: 0.0191, Train Acc: 0.9940, Test Acc: 0.9367\n",
            "Epoch 21, Loss: 0.0196, Train Acc: 0.9945, Test Acc: 0.9611\n",
            "Epoch 22, Loss: 0.0178, Train Acc: 0.9947, Test Acc: 0.9178\n",
            "Epoch 23, Loss: 0.0157, Train Acc: 0.9952, Test Acc: 0.9522\n",
            "Epoch 24, Loss: 0.0172, Train Acc: 0.9946, Test Acc: 0.9453\n",
            "Epoch 25, Loss: 0.0158, Train Acc: 0.9952, Test Acc: 0.9133\n",
            "Epoch 26, Loss: 0.0159, Train Acc: 0.9956, Test Acc: 0.9322\n",
            "Epoch 27, Loss: 0.0133, Train Acc: 0.9959, Test Acc: 0.9312\n",
            "Epoch 28, Loss: 0.0136, Train Acc: 0.9956, Test Acc: 0.9493\n",
            "Epoch 29, Loss: 0.0137, Train Acc: 0.9954, Test Acc: 0.9288\n",
            "Epoch 30, Loss: 0.0126, Train Acc: 0.9967, Test Acc: 0.9487\n",
            "Epoch 31, Loss: 0.0131, Train Acc: 0.9956, Test Acc: 0.9316\n",
            "Epoch 32, Loss: 0.0111, Train Acc: 0.9960, Test Acc: 0.9475\n",
            "Epoch 33, Loss: 0.0128, Train Acc: 0.9968, Test Acc: 0.9165\n",
            "Epoch 34, Loss: 0.0113, Train Acc: 0.9956, Test Acc: 0.9312\n",
            "Epoch 35, Loss: 0.0102, Train Acc: 0.9966, Test Acc: 0.9248\n",
            "Epoch 36, Loss: 0.0107, Train Acc: 0.9960, Test Acc: 0.9375\n",
            "Epoch 37, Loss: 0.0131, Train Acc: 0.9969, Test Acc: 0.9207\n",
            "Epoch 38, Loss: 0.0101, Train Acc: 0.9967, Test Acc: 0.9292\n",
            "Epoch 39, Loss: 0.0108, Train Acc: 0.9966, Test Acc: 0.9542\n",
            "Epoch 40, Loss: 0.0100, Train Acc: 0.9961, Test Acc: 0.9407\n",
            "Epoch 41, Loss: 0.0098, Train Acc: 0.9960, Test Acc: 0.9255\n",
            "Epoch 42, Loss: 0.0093, Train Acc: 0.9971, Test Acc: 0.9514\n",
            "Epoch 43, Loss: 0.0101, Train Acc: 0.9967, Test Acc: 0.9135\n",
            "Epoch 44, Loss: 0.0092, Train Acc: 0.9966, Test Acc: 0.9295\n",
            "Epoch 45, Loss: 0.0098, Train Acc: 0.9972, Test Acc: 0.9221\n",
            "Epoch 46, Loss: 0.0093, Train Acc: 0.9979, Test Acc: 0.9464\n",
            "Epoch 47, Loss: 0.0082, Train Acc: 0.9977, Test Acc: 0.9304\n",
            "Epoch 48, Loss: 0.0078, Train Acc: 0.9978, Test Acc: 0.9241\n",
            "Epoch 49, Loss: 0.0090, Train Acc: 0.9972, Test Acc: 0.9140\n",
            "Epoch 50, Loss: 0.0098, Train Acc: 0.9978, Test Acc: 0.9108\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(30 * 12 * 12, 100)  # 12x12 크기로 줄어듦\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 30 * 12 * 12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(20),  # 20도 회전\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1bootOoG8JN",
        "outputId": "ced32f55-42dd-4466-d65d-4f629f4ab4e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.3123, Train Acc: 0.9548, Test Acc: 0.8960\n",
            "Epoch 2, Loss: 0.1278, Train Acc: 0.9653, Test Acc: 0.9507\n",
            "Epoch 3, Loss: 0.1056, Train Acc: 0.9732, Test Acc: 0.9536\n",
            "Epoch 4, Loss: 0.0906, Train Acc: 0.9739, Test Acc: 0.9000\n",
            "Epoch 5, Loss: 0.0850, Train Acc: 0.9737, Test Acc: 0.9678\n",
            "Epoch 6, Loss: 0.0775, Train Acc: 0.9774, Test Acc: 0.9363\n",
            "Epoch 7, Loss: 0.0736, Train Acc: 0.9797, Test Acc: 0.9651\n",
            "Epoch 8, Loss: 0.0657, Train Acc: 0.9796, Test Acc: 0.9714\n",
            "Epoch 9, Loss: 0.0632, Train Acc: 0.9794, Test Acc: 0.9712\n",
            "Epoch 10, Loss: 0.0606, Train Acc: 0.9817, Test Acc: 0.9758\n",
            "Epoch 11, Loss: 0.0572, Train Acc: 0.9835, Test Acc: 0.9738\n",
            "Epoch 12, Loss: 0.0553, Train Acc: 0.9824, Test Acc: 0.9684\n",
            "Epoch 13, Loss: 0.0552, Train Acc: 0.9828, Test Acc: 0.9759\n",
            "Epoch 14, Loss: 0.0520, Train Acc: 0.9842, Test Acc: 0.9754\n",
            "Epoch 15, Loss: 0.0512, Train Acc: 0.9863, Test Acc: 0.9794\n",
            "Epoch 16, Loss: 0.0465, Train Acc: 0.9839, Test Acc: 0.9844\n",
            "Epoch 17, Loss: 0.0447, Train Acc: 0.9861, Test Acc: 0.9842\n",
            "Epoch 18, Loss: 0.0455, Train Acc: 0.9864, Test Acc: 0.9765\n",
            "Epoch 19, Loss: 0.0438, Train Acc: 0.9859, Test Acc: 0.9736\n",
            "Epoch 20, Loss: 0.0435, Train Acc: 0.9869, Test Acc: 0.9709\n",
            "Epoch 21, Loss: 0.0404, Train Acc: 0.9877, Test Acc: 0.9819\n",
            "Epoch 22, Loss: 0.0402, Train Acc: 0.9871, Test Acc: 0.9750\n",
            "Epoch 23, Loss: 0.0388, Train Acc: 0.9885, Test Acc: 0.9551\n",
            "Epoch 24, Loss: 0.0392, Train Acc: 0.9891, Test Acc: 0.9786\n",
            "Epoch 25, Loss: 0.0369, Train Acc: 0.9886, Test Acc: 0.9745\n",
            "Epoch 26, Loss: 0.0369, Train Acc: 0.9892, Test Acc: 0.9681\n",
            "Epoch 27, Loss: 0.0354, Train Acc: 0.9895, Test Acc: 0.9751\n",
            "Epoch 28, Loss: 0.0353, Train Acc: 0.9888, Test Acc: 0.9649\n",
            "Epoch 29, Loss: 0.0336, Train Acc: 0.9897, Test Acc: 0.9607\n",
            "Epoch 30, Loss: 0.0345, Train Acc: 0.9896, Test Acc: 0.9687\n",
            "Epoch 31, Loss: 0.0332, Train Acc: 0.9892, Test Acc: 0.9506\n",
            "Epoch 32, Loss: 0.0329, Train Acc: 0.9897, Test Acc: 0.9619\n",
            "Epoch 33, Loss: 0.0300, Train Acc: 0.9902, Test Acc: 0.9599\n",
            "Epoch 34, Loss: 0.0320, Train Acc: 0.9915, Test Acc: 0.9581\n",
            "Epoch 35, Loss: 0.0300, Train Acc: 0.9912, Test Acc: 0.9680\n",
            "Epoch 36, Loss: 0.0296, Train Acc: 0.9907, Test Acc: 0.9709\n",
            "Epoch 37, Loss: 0.0282, Train Acc: 0.9902, Test Acc: 0.9720\n",
            "Epoch 38, Loss: 0.0300, Train Acc: 0.9913, Test Acc: 0.9619\n",
            "Epoch 39, Loss: 0.0285, Train Acc: 0.9916, Test Acc: 0.9649\n",
            "Epoch 40, Loss: 0.0282, Train Acc: 0.9921, Test Acc: 0.9480\n",
            "Epoch 41, Loss: 0.0280, Train Acc: 0.9914, Test Acc: 0.9706\n",
            "Epoch 42, Loss: 0.0278, Train Acc: 0.9917, Test Acc: 0.9521\n",
            "Epoch 43, Loss: 0.0279, Train Acc: 0.9917, Test Acc: 0.9669\n",
            "Epoch 44, Loss: 0.0274, Train Acc: 0.9922, Test Acc: 0.9516\n",
            "Epoch 45, Loss: 0.0262, Train Acc: 0.9921, Test Acc: 0.9568\n",
            "Epoch 46, Loss: 0.0262, Train Acc: 0.9922, Test Acc: 0.9618\n",
            "Epoch 47, Loss: 0.0256, Train Acc: 0.9918, Test Acc: 0.9546\n",
            "Epoch 48, Loss: 0.0253, Train Acc: 0.9926, Test Acc: 0.9702\n",
            "Epoch 49, Loss: 0.0245, Train Acc: 0.9927, Test Acc: 0.9547\n",
            "Epoch 50, Loss: 0.0255, Train Acc: 0.9926, Test Acc: 0.9237\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)  # 과적합 방지\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        x = F.relu(self.batch_norm(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\"./data\", train=True, download=True,\n",
        "                   transform=transforms.ToTensor()), batch_size=100, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqze0yNNG_hb",
        "outputId": "27251ab5-f7c5-4ac4-c887-dff47c07c206"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.0919, Train Acc: 0.9917, Test Acc: 0.9905\n",
            "Epoch 2, Loss: 0.0376, Train Acc: 0.9952, Test Acc: 0.9934\n",
            "Epoch 3, Loss: 0.0260, Train Acc: 0.9964, Test Acc: 0.9945\n",
            "Epoch 4, Loss: 0.0218, Train Acc: 0.9969, Test Acc: 0.9939\n",
            "Epoch 5, Loss: 0.0172, Train Acc: 0.9966, Test Acc: 0.9938\n",
            "Epoch 6, Loss: 0.0144, Train Acc: 0.9974, Test Acc: 0.9934\n",
            "Epoch 7, Loss: 0.0132, Train Acc: 0.9981, Test Acc: 0.9936\n",
            "Epoch 8, Loss: 0.0102, Train Acc: 0.9986, Test Acc: 0.9946\n",
            "Epoch 9, Loss: 0.0102, Train Acc: 0.9983, Test Acc: 0.9934\n",
            "Epoch 10, Loss: 0.0086, Train Acc: 0.9990, Test Acc: 0.9946\n",
            "Epoch 11, Loss: 0.0075, Train Acc: 0.9991, Test Acc: 0.9948\n",
            "Epoch 12, Loss: 0.0071, Train Acc: 0.9994, Test Acc: 0.9951\n",
            "Epoch 13, Loss: 0.0053, Train Acc: 0.9994, Test Acc: 0.9954\n",
            "Epoch 14, Loss: 0.0064, Train Acc: 0.9995, Test Acc: 0.9950\n",
            "Epoch 15, Loss: 0.0059, Train Acc: 0.9991, Test Acc: 0.9948\n",
            "Epoch 16, Loss: 0.0064, Train Acc: 0.9996, Test Acc: 0.9954\n",
            "Epoch 17, Loss: 0.0043, Train Acc: 0.9996, Test Acc: 0.9955\n",
            "Epoch 18, Loss: 0.0034, Train Acc: 0.9997, Test Acc: 0.9949\n",
            "Epoch 19, Loss: 0.0039, Train Acc: 0.9997, Test Acc: 0.9945\n",
            "Epoch 20, Loss: 0.0032, Train Acc: 0.9997, Test Acc: 0.9948\n",
            "Epoch 21, Loss: 0.0027, Train Acc: 0.9993, Test Acc: 0.9944\n",
            "Epoch 22, Loss: 0.0037, Train Acc: 0.9993, Test Acc: 0.9941\n",
            "Epoch 23, Loss: 0.0035, Train Acc: 0.9998, Test Acc: 0.9945\n",
            "Epoch 24, Loss: 0.0033, Train Acc: 0.9999, Test Acc: 0.9953\n",
            "Epoch 25, Loss: 0.0032, Train Acc: 0.9998, Test Acc: 0.9946\n",
            "Epoch 26, Loss: 0.0025, Train Acc: 0.9998, Test Acc: 0.9947\n",
            "Epoch 27, Loss: 0.0025, Train Acc: 0.9999, Test Acc: 0.9955\n",
            "Epoch 28, Loss: 0.0021, Train Acc: 0.9997, Test Acc: 0.9950\n",
            "Epoch 29, Loss: 0.0041, Train Acc: 0.9999, Test Acc: 0.9948\n",
            "Epoch 30, Loss: 0.0019, Train Acc: 0.9999, Test Acc: 0.9946\n",
            "Epoch 31, Loss: 0.0027, Train Acc: 0.9997, Test Acc: 0.9945\n",
            "Epoch 32, Loss: 0.0026, Train Acc: 0.9999, Test Acc: 0.9945\n",
            "Epoch 33, Loss: 0.0013, Train Acc: 0.9998, Test Acc: 0.9954\n",
            "Epoch 34, Loss: 0.0025, Train Acc: 0.9994, Test Acc: 0.9940\n",
            "Epoch 35, Loss: 0.0028, Train Acc: 0.9996, Test Acc: 0.9945\n",
            "Epoch 36, Loss: 0.0033, Train Acc: 1.0000, Test Acc: 0.9953\n",
            "Epoch 37, Loss: 0.0016, Train Acc: 0.9998, Test Acc: 0.9944\n",
            "Epoch 38, Loss: 0.0022, Train Acc: 0.9998, Test Acc: 0.9950\n",
            "Epoch 39, Loss: 0.0023, Train Acc: 1.0000, Test Acc: 0.9952\n",
            "Epoch 40, Loss: 0.0015, Train Acc: 0.9999, Test Acc: 0.9948\n",
            "Epoch 41, Loss: 0.0025, Train Acc: 0.9998, Test Acc: 0.9938\n",
            "Epoch 42, Loss: 0.0014, Train Acc: 1.0000, Test Acc: 0.9952\n",
            "Epoch 43, Loss: 0.0016, Train Acc: 0.9999, Test Acc: 0.9944\n",
            "Epoch 44, Loss: 0.0015, Train Acc: 0.9999, Test Acc: 0.9948\n",
            "Epoch 45, Loss: 0.0026, Train Acc: 0.9998, Test Acc: 0.9942\n",
            "Epoch 46, Loss: 0.0011, Train Acc: 0.9995, Test Acc: 0.9945\n",
            "Epoch 47, Loss: 0.0016, Train Acc: 1.0000, Test Acc: 0.9939\n",
            "Epoch 48, Loss: 0.0010, Train Acc: 0.9999, Test Acc: 0.9942\n",
            "Epoch 49, Loss: 0.0010, Train Acc: 0.9997, Test Acc: 0.9951\n",
            "Epoch 50, Loss: 0.0024, Train Acc: 1.0000, Test Acc: 0.9957\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)  # 과적합 방지\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        x = F.relu(self.batch_norm(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(20),  # 20도 회전\n",
        "    #transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMwn4_0jHRff",
        "outputId": "d1affb37-2975-4889-8ddc-72fdf0824db4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.1217, Train Acc: 0.9853, Test Acc: 0.2064\n",
            "Epoch 2, Loss: 0.0567, Train Acc: 0.9828, Test Acc: 0.3905\n",
            "Epoch 3, Loss: 0.0443, Train Acc: 0.9913, Test Acc: 0.5525\n",
            "Epoch 4, Loss: 0.0397, Train Acc: 0.9935, Test Acc: 0.5710\n",
            "Epoch 5, Loss: 0.0343, Train Acc: 0.9922, Test Acc: 0.6720\n",
            "Epoch 6, Loss: 0.0306, Train Acc: 0.9922, Test Acc: 0.9481\n",
            "Epoch 7, Loss: 0.0277, Train Acc: 0.9941, Test Acc: 0.8452\n",
            "Epoch 8, Loss: 0.0258, Train Acc: 0.9940, Test Acc: 0.9546\n",
            "Epoch 9, Loss: 0.0262, Train Acc: 0.9953, Test Acc: 0.9155\n",
            "Epoch 10, Loss: 0.0234, Train Acc: 0.9967, Test Acc: 0.9242\n",
            "Epoch 11, Loss: 0.0205, Train Acc: 0.9966, Test Acc: 0.9037\n",
            "Epoch 12, Loss: 0.0192, Train Acc: 0.9964, Test Acc: 0.9668\n",
            "Epoch 13, Loss: 0.0200, Train Acc: 0.9962, Test Acc: 0.9006\n",
            "Epoch 14, Loss: 0.0180, Train Acc: 0.9973, Test Acc: 0.9513\n",
            "Epoch 15, Loss: 0.0157, Train Acc: 0.9968, Test Acc: 0.9603\n",
            "Epoch 16, Loss: 0.0156, Train Acc: 0.9968, Test Acc: 0.9586\n",
            "Epoch 17, Loss: 0.0137, Train Acc: 0.9976, Test Acc: 0.9668\n",
            "Epoch 18, Loss: 0.0167, Train Acc: 0.9973, Test Acc: 0.9553\n",
            "Epoch 19, Loss: 0.0150, Train Acc: 0.9979, Test Acc: 0.9549\n",
            "Epoch 20, Loss: 0.0129, Train Acc: 0.9980, Test Acc: 0.9753\n",
            "Epoch 21, Loss: 0.0123, Train Acc: 0.9984, Test Acc: 0.9772\n",
            "Epoch 22, Loss: 0.0133, Train Acc: 0.9977, Test Acc: 0.9533\n",
            "Epoch 23, Loss: 0.0104, Train Acc: 0.9981, Test Acc: 0.9603\n",
            "Epoch 24, Loss: 0.0104, Train Acc: 0.9982, Test Acc: 0.9788\n",
            "Epoch 25, Loss: 0.0099, Train Acc: 0.9981, Test Acc: 0.9801\n",
            "Epoch 26, Loss: 0.0115, Train Acc: 0.9982, Test Acc: 0.9720\n",
            "Epoch 27, Loss: 0.0100, Train Acc: 0.9983, Test Acc: 0.9734\n",
            "Epoch 28, Loss: 0.0099, Train Acc: 0.9985, Test Acc: 0.9738\n",
            "Epoch 29, Loss: 0.0099, Train Acc: 0.9987, Test Acc: 0.9788\n",
            "Epoch 30, Loss: 0.0091, Train Acc: 0.9984, Test Acc: 0.9770\n",
            "Epoch 31, Loss: 0.0079, Train Acc: 0.9987, Test Acc: 0.9760\n",
            "Epoch 32, Loss: 0.0084, Train Acc: 0.9983, Test Acc: 0.9738\n",
            "Epoch 33, Loss: 0.0110, Train Acc: 0.9984, Test Acc: 0.9516\n",
            "Epoch 34, Loss: 0.0078, Train Acc: 0.9987, Test Acc: 0.9498\n",
            "Epoch 35, Loss: 0.0083, Train Acc: 0.9990, Test Acc: 0.9822\n",
            "Epoch 36, Loss: 0.0075, Train Acc: 0.9990, Test Acc: 0.9686\n",
            "Epoch 37, Loss: 0.0065, Train Acc: 0.9992, Test Acc: 0.9746\n",
            "Epoch 38, Loss: 0.0074, Train Acc: 0.9987, Test Acc: 0.9530\n",
            "Epoch 39, Loss: 0.0089, Train Acc: 0.9987, Test Acc: 0.9778\n",
            "Epoch 40, Loss: 0.0075, Train Acc: 0.9993, Test Acc: 0.9636\n",
            "Epoch 41, Loss: 0.0072, Train Acc: 0.9993, Test Acc: 0.9666\n",
            "Epoch 42, Loss: 0.0085, Train Acc: 0.9991, Test Acc: 0.9645\n",
            "Epoch 43, Loss: 0.0066, Train Acc: 0.9993, Test Acc: 0.9435\n",
            "Epoch 44, Loss: 0.0072, Train Acc: 0.9993, Test Acc: 0.9619\n",
            "Epoch 45, Loss: 0.0063, Train Acc: 0.9990, Test Acc: 0.9514\n",
            "Epoch 46, Loss: 0.0056, Train Acc: 0.9992, Test Acc: 0.9613\n",
            "Epoch 47, Loss: 0.0064, Train Acc: 0.9992, Test Acc: 0.9675\n",
            "Epoch 48, Loss: 0.0055, Train Acc: 0.9990, Test Acc: 0.9781\n",
            "Epoch 49, Loss: 0.0056, Train Acc: 0.9990, Test Acc: 0.9736\n",
            "Epoch 50, Loss: 0.0049, Train Acc: 0.9993, Test Acc: 0.9503\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)  # 과적합 방지\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        x = F.relu(self.batch_norm(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    #transforms.RandomRotation(20),  # 20도 회전\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVj7Vht0Hi4E",
        "outputId": "0cfd54f5-c827-4b48-eeff-0fbd99fc8361"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.1095, Train Acc: 0.9880, Test Acc: 0.5729\n",
            "Epoch 2, Loss: 0.0484, Train Acc: 0.9895, Test Acc: 0.5109\n",
            "Epoch 3, Loss: 0.0400, Train Acc: 0.9916, Test Acc: 0.6303\n",
            "Epoch 4, Loss: 0.0331, Train Acc: 0.9930, Test Acc: 0.9120\n",
            "Epoch 5, Loss: 0.0307, Train Acc: 0.9940, Test Acc: 0.9215\n",
            "Epoch 6, Loss: 0.0271, Train Acc: 0.9955, Test Acc: 0.9034\n",
            "Epoch 7, Loss: 0.0252, Train Acc: 0.9947, Test Acc: 0.8435\n",
            "Epoch 8, Loss: 0.0236, Train Acc: 0.9956, Test Acc: 0.9221\n",
            "Epoch 9, Loss: 0.0207, Train Acc: 0.9966, Test Acc: 0.8901\n",
            "Epoch 10, Loss: 0.0196, Train Acc: 0.9951, Test Acc: 0.9529\n",
            "Epoch 11, Loss: 0.0195, Train Acc: 0.9955, Test Acc: 0.9588\n",
            "Epoch 12, Loss: 0.0172, Train Acc: 0.9970, Test Acc: 0.9154\n",
            "Epoch 13, Loss: 0.0185, Train Acc: 0.9973, Test Acc: 0.9503\n",
            "Epoch 14, Loss: 0.0158, Train Acc: 0.9966, Test Acc: 0.9581\n",
            "Epoch 15, Loss: 0.0152, Train Acc: 0.9972, Test Acc: 0.9103\n",
            "Epoch 16, Loss: 0.0138, Train Acc: 0.9979, Test Acc: 0.9059\n",
            "Epoch 17, Loss: 0.0134, Train Acc: 0.9977, Test Acc: 0.9495\n",
            "Epoch 18, Loss: 0.0134, Train Acc: 0.9977, Test Acc: 0.9351\n",
            "Epoch 19, Loss: 0.0118, Train Acc: 0.9978, Test Acc: 0.9077\n",
            "Epoch 20, Loss: 0.0125, Train Acc: 0.9970, Test Acc: 0.9329\n",
            "Epoch 21, Loss: 0.0112, Train Acc: 0.9979, Test Acc: 0.9180\n",
            "Epoch 22, Loss: 0.0105, Train Acc: 0.9979, Test Acc: 0.8791\n",
            "Epoch 23, Loss: 0.0110, Train Acc: 0.9980, Test Acc: 0.9817\n",
            "Epoch 24, Loss: 0.0105, Train Acc: 0.9982, Test Acc: 0.9417\n",
            "Epoch 25, Loss: 0.0110, Train Acc: 0.9985, Test Acc: 0.9346\n",
            "Epoch 26, Loss: 0.0104, Train Acc: 0.9983, Test Acc: 0.9133\n",
            "Epoch 27, Loss: 0.0090, Train Acc: 0.9983, Test Acc: 0.9345\n",
            "Epoch 28, Loss: 0.0088, Train Acc: 0.9986, Test Acc: 0.9481\n",
            "Epoch 29, Loss: 0.0083, Train Acc: 0.9982, Test Acc: 0.9703\n",
            "Epoch 30, Loss: 0.0080, Train Acc: 0.9986, Test Acc: 0.9641\n",
            "Epoch 31, Loss: 0.0082, Train Acc: 0.9989, Test Acc: 0.9562\n",
            "Epoch 32, Loss: 0.0080, Train Acc: 0.9987, Test Acc: 0.9602\n",
            "Epoch 33, Loss: 0.0089, Train Acc: 0.9988, Test Acc: 0.9706\n",
            "Epoch 34, Loss: 0.0070, Train Acc: 0.9991, Test Acc: 0.9552\n",
            "Epoch 35, Loss: 0.0070, Train Acc: 0.9986, Test Acc: 0.9596\n",
            "Epoch 36, Loss: 0.0071, Train Acc: 0.9990, Test Acc: 0.9453\n",
            "Epoch 37, Loss: 0.0081, Train Acc: 0.9985, Test Acc: 0.9499\n",
            "Epoch 38, Loss: 0.0075, Train Acc: 0.9990, Test Acc: 0.9598\n",
            "Epoch 39, Loss: 0.0056, Train Acc: 0.9990, Test Acc: 0.9726\n",
            "Epoch 40, Loss: 0.0075, Train Acc: 0.9990, Test Acc: 0.9474\n",
            "Epoch 41, Loss: 0.0058, Train Acc: 0.9988, Test Acc: 0.9796\n",
            "Epoch 42, Loss: 0.0073, Train Acc: 0.9984, Test Acc: 0.9600\n",
            "Epoch 43, Loss: 0.0065, Train Acc: 0.9987, Test Acc: 0.9716\n",
            "Epoch 44, Loss: 0.0056, Train Acc: 0.9990, Test Acc: 0.9649\n",
            "Epoch 45, Loss: 0.0058, Train Acc: 0.9993, Test Acc: 0.9608\n",
            "Epoch 46, Loss: 0.0059, Train Acc: 0.9993, Test Acc: 0.9007\n",
            "Epoch 47, Loss: 0.0074, Train Acc: 0.9993, Test Acc: 0.9384\n",
            "Epoch 48, Loss: 0.0052, Train Acc: 0.9990, Test Acc: 0.9010\n",
            "Epoch 49, Loss: 0.0057, Train Acc: 0.9991, Test Acc: 0.9540\n",
            "Epoch 50, Loss: 0.0049, Train Acc: 0.9993, Test Acc: 0.9260\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ✅ CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ CNN 모델 정의\n",
        "class SimpleConvNet(nn.Module):\n",
        "    class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # 14x14 -> 14x14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)  # 과적합 방지\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        x = F.relu(self.batch_norm(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ✅ 모델 생성 & CUDA로 이동\n",
        "model = SimpleConvNet().to(device)\n",
        "\n",
        "# ✅ 데이터셋 로드 (PyTorch 제공 MNIST)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(20),  # 20도 회전\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 기울기 변형 및 크기 조정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor()), batch_size=1000, shuffle=False)\n",
        "# ✅ 옵티마이저 & 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 사용\n",
        "\n",
        "# ✅ 정확도 계산 함수\n",
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 역전파 비활성화 (메모리 절약)\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)  # 가장 높은 값의 인덱스 선택\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# ✅ 학습 루프\n",
        "epochs = 50  # 학습 횟수 증가\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # ✅ 학습 & 테스트 정확도 출력\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    test_acc = compute_accuracy(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WakMsqrSHmEl",
        "outputId": "1942222c-4a25-40b7-aaa1-9a38cd4056ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.1492, Train Acc: 0.9683, Test Acc: 0.2465\n",
            "Epoch 2, Loss: 0.0717, Train Acc: 0.9830, Test Acc: 0.3350\n",
            "Epoch 3, Loss: 0.0569, Train Acc: 0.9875, Test Acc: 0.6807\n",
            "Epoch 4, Loss: 0.0514, Train Acc: 0.9871, Test Acc: 0.8912\n",
            "Epoch 5, Loss: 0.0479, Train Acc: 0.9893, Test Acc: 0.8799\n",
            "Epoch 6, Loss: 0.0408, Train Acc: 0.9884, Test Acc: 0.8868\n",
            "Epoch 7, Loss: 0.0413, Train Acc: 0.9920, Test Acc: 0.9630\n",
            "Epoch 8, Loss: 0.0364, Train Acc: 0.9918, Test Acc: 0.9553\n",
            "Epoch 9, Loss: 0.0369, Train Acc: 0.9923, Test Acc: 0.8952\n",
            "Epoch 10, Loss: 0.0337, Train Acc: 0.9927, Test Acc: 0.9031\n",
            "Epoch 11, Loss: 0.0321, Train Acc: 0.9923, Test Acc: 0.9478\n",
            "Epoch 12, Loss: 0.0305, Train Acc: 0.9933, Test Acc: 0.9295\n",
            "Epoch 13, Loss: 0.0296, Train Acc: 0.9934, Test Acc: 0.9333\n",
            "Epoch 14, Loss: 0.0292, Train Acc: 0.9931, Test Acc: 0.9204\n",
            "Epoch 15, Loss: 0.0285, Train Acc: 0.9937, Test Acc: 0.9364\n",
            "Epoch 16, Loss: 0.0301, Train Acc: 0.9950, Test Acc: 0.9468\n",
            "Epoch 17, Loss: 0.0232, Train Acc: 0.9942, Test Acc: 0.9498\n",
            "Epoch 18, Loss: 0.0258, Train Acc: 0.9951, Test Acc: 0.9268\n",
            "Epoch 19, Loss: 0.0217, Train Acc: 0.9948, Test Acc: 0.9609\n",
            "Epoch 20, Loss: 0.0254, Train Acc: 0.9951, Test Acc: 0.9699\n",
            "Epoch 21, Loss: 0.0220, Train Acc: 0.9956, Test Acc: 0.9718\n",
            "Epoch 22, Loss: 0.0226, Train Acc: 0.9949, Test Acc: 0.9537\n",
            "Epoch 23, Loss: 0.0221, Train Acc: 0.9956, Test Acc: 0.9793\n",
            "Epoch 24, Loss: 0.0206, Train Acc: 0.9956, Test Acc: 0.9786\n",
            "Epoch 25, Loss: 0.0207, Train Acc: 0.9960, Test Acc: 0.9822\n",
            "Epoch 26, Loss: 0.0219, Train Acc: 0.9960, Test Acc: 0.9727\n",
            "Epoch 27, Loss: 0.0208, Train Acc: 0.9967, Test Acc: 0.9832\n",
            "Epoch 28, Loss: 0.0203, Train Acc: 0.9966, Test Acc: 0.9793\n",
            "Epoch 29, Loss: 0.0195, Train Acc: 0.9959, Test Acc: 0.9803\n",
            "Epoch 30, Loss: 0.0196, Train Acc: 0.9962, Test Acc: 0.9645\n",
            "Epoch 31, Loss: 0.0190, Train Acc: 0.9962, Test Acc: 0.9489\n",
            "Epoch 32, Loss: 0.0180, Train Acc: 0.9959, Test Acc: 0.9440\n",
            "Epoch 33, Loss: 0.0170, Train Acc: 0.9966, Test Acc: 0.9652\n",
            "Epoch 34, Loss: 0.0175, Train Acc: 0.9967, Test Acc: 0.9554\n",
            "Epoch 35, Loss: 0.0167, Train Acc: 0.9961, Test Acc: 0.9739\n",
            "Epoch 36, Loss: 0.0172, Train Acc: 0.9964, Test Acc: 0.9625\n",
            "Epoch 37, Loss: 0.0167, Train Acc: 0.9966, Test Acc: 0.9584\n",
            "Epoch 38, Loss: 0.0167, Train Acc: 0.9969, Test Acc: 0.9460\n",
            "Epoch 39, Loss: 0.0150, Train Acc: 0.9970, Test Acc: 0.9580\n",
            "Epoch 40, Loss: 0.0170, Train Acc: 0.9965, Test Acc: 0.9560\n",
            "Epoch 41, Loss: 0.0167, Train Acc: 0.9969, Test Acc: 0.9535\n",
            "Epoch 42, Loss: 0.0137, Train Acc: 0.9966, Test Acc: 0.9100\n",
            "Epoch 43, Loss: 0.0159, Train Acc: 0.9969, Test Acc: 0.9750\n",
            "Epoch 44, Loss: 0.0163, Train Acc: 0.9974, Test Acc: 0.9461\n",
            "Epoch 45, Loss: 0.0148, Train Acc: 0.9965, Test Acc: 0.9148\n",
            "Epoch 46, Loss: 0.0136, Train Acc: 0.9968, Test Acc: 0.9326\n",
            "Epoch 47, Loss: 0.0139, Train Acc: 0.9970, Test Acc: 0.9506\n",
            "Epoch 48, Loss: 0.0142, Train Acc: 0.9968, Test Acc: 0.9679\n",
            "Epoch 49, Loss: 0.0160, Train Acc: 0.9970, Test Acc: 0.9339\n",
            "Epoch 50, Loss: 0.0117, Train Acc: 0.9976, Test Acc: 0.9584\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0UWQ5rXFSG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}